<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Gradient Boosting - Chux&#x27;s Notebook</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="katex.min.css">

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="intro.html">Introduction</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">1.</strong> Recommender Systems</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="gradient_boosting.html" class="active"><strong aria-hidden="true">1.1.</strong> Gradient Boosting</a></li><li class="chapter-item expanded "><a href="tfidf.html"><strong aria-hidden="true">1.2.</strong> TF-IDF</a></li><li class="chapter-item expanded "><a href="cross_encoders.html"><strong aria-hidden="true">1.3.</strong> Cross Encoders</a></li><li class="chapter-item expanded "><a href="sentence_transformers.html"><strong aria-hidden="true">1.4.</strong> SentenceTransformers</a></li></ol></li><li class="chapter-item expanded "><a href="ab_test/init.html"><strong aria-hidden="true">2.</strong> AB Testing</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ab_test/examples.html"><strong aria-hidden="true">2.1.</strong> Examples</a></li><li class="chapter-item expanded "><a href="ab_test/power_analysis.html"><strong aria-hidden="true">2.2.</strong> Power Analysis</a></li></ol></li><li class="chapter-item expanded "><a href="llm/llm.html"><strong aria-hidden="true">3.</strong> LLMs</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="llm/fine_tuning.html"><strong aria-hidden="true">3.1.</strong> Fine-tuning</a></li><li class="chapter-item expanded "><a href="llm/useful_models.html"><strong aria-hidden="true">3.2.</strong> Useful Models</a></li><li class="chapter-item expanded "><a href="llm/encoder_vs_decoder.html"><strong aria-hidden="true">3.3.</strong> Encoder vs Decoder</a></li></ol></li><li class="chapter-item expanded "><a href="misc.html"><strong aria-hidden="true">4.</strong> Miscellaneous</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="misc/bradley-terry.html"><strong aria-hidden="true">4.1.</strong> Bradley-Terry Model</a></li></ol></li><li class="chapter-item expanded "><a href="identities.html"><strong aria-hidden="true">5.</strong> Identities</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="identities/sigmoid.html"><strong aria-hidden="true">5.1.</strong> Sigmoid</a></li><li class="chapter-item expanded "><a href="identities/statistics.html"><strong aria-hidden="true">5.2.</strong> Statistics</a></li></ol></li><li class="chapter-item expanded "><a href="papers.html"><strong aria-hidden="true">6.</strong> Papers</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="papers/burges_2010.html"><strong aria-hidden="true">6.1.</strong> Burges 2010 - RankNET to LambdaMART</a></li><li class="chapter-item expanded "><a href="papers/schroff_2015.html"><strong aria-hidden="true">6.2.</strong> Schroff 2015 - FaceNET</a></li><li class="chapter-item expanded "><a href="papers/schnabel_2016.html"><strong aria-hidden="true">6.3.</strong> Schnabel 2016 - Recs as Treatments</a></li><li class="chapter-item expanded "><a href="papers/guo_2017.html"><strong aria-hidden="true">6.4.</strong> Guo 2017 - DeepFM</a></li><li class="chapter-item expanded "><a href="papers/hamilton_2017.html"><strong aria-hidden="true">6.5.</strong> Hamilton 2017 - GraphSAGE</a></li><li class="chapter-item expanded "><a href="papers/ma_2018.html"><strong aria-hidden="true">6.6.</strong> Ma 2018 - Entire Space Multi-Task Model</a></li><li class="chapter-item expanded "><a href="papers/reimers_2019.html"><strong aria-hidden="true">6.7.</strong> Reimers 2019 - Sentence-BERT</a></li><li class="chapter-item expanded "><a href="papers/he_2020.html"><strong aria-hidden="true">6.8.</strong> He 2020 - LightGCN</a></li><li class="chapter-item expanded "><a href="papers/lewis_2020.html"><strong aria-hidden="true">6.9.</strong> Lewis 2020 - Retrieval Augmented Generation</a></li><li class="chapter-item expanded "><a href="papers/gao_2021.html"><strong aria-hidden="true">6.10.</strong> Gao 2021 - SimCSE</a></li><li class="chapter-item expanded "><a href="papers/weng_2021.html"><strong aria-hidden="true">6.11.</strong> Weng 2021 - Contrastive Representation Learning</a></li><li class="chapter-item expanded "><a href="papers/dao_2022.html"><strong aria-hidden="true">6.12.</strong> Dao 2022 - Flash Attention</a></li><li class="chapter-item expanded "><a href="papers/tunstall_2022.html"><strong aria-hidden="true">6.13.</strong> Tunstall 2022 - SetFit</a></li><li class="chapter-item expanded "><a href="papers/rafailov_2023.html"><strong aria-hidden="true">6.14.</strong> Rafailov 2023 - Direct Preference Optimization</a></li><li class="chapter-item expanded "><a href="papers/borisyuk_2024.html"><strong aria-hidden="true">6.15.</strong> Borisyuk 2024 - GNN at LinkedIn</a></li><li class="chapter-item expanded "><a href="papers/liu_2023.html"><strong aria-hidden="true">6.16.</strong> Liu 2023 - Meaning Representations from Trajectories</a></li></ol></li><li class="chapter-item expanded "><a href="nlp_course/intro.html"><strong aria-hidden="true">7.</strong> NLP Course</a></li><li class="chapter-item expanded "><a href="database_course/intro.html"><strong aria-hidden="true">8.</strong> Database Course</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="database_course/lecture01.html"><strong aria-hidden="true">8.1.</strong> Lecture 1</a></li><li class="chapter-item expanded "><a href="database_course/lecture02.html"><strong aria-hidden="true">8.2.</strong> Lecture 2</a></li><li class="chapter-item expanded "><a href="database_course/lecture03.html"><strong aria-hidden="true">8.3.</strong> Lecture 3</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Chux&#x27;s Notebook</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h2 id="lightgbm-memory"><a class="header" href="#lightgbm-memory">LightGBM Memory</a></h2>
<p>TLDR: Solutions for memory issues during training of a LightGBM model:</p>
<ol>
<li>Cast numeric values into <code>np.float32</code> to save data space</li>
<li>Keep <code>num_leaves &lt;= 100</code> (or some reasonable number)</li>
<li>If feature dimension is large (e.g. <code>M &gt;= 1000</code>), try <code>colsample_bytree = 0.1</code>, although this might not help too much if the bottleneck is during bin histogram construction (rather than the actual training)</li>
<li>If number of rows and features are both large (e.g. <code>N &gt;= 1_000_000</code> and <code>M &gt;= 1000</code>, i.e. <code>&gt;= 4 GB</code>) then the data itself is taking up a lot of memory. It would be worthwhile to put the data on disk and use <code>lgb.Dataset</code> by providing the file path as the data argument instead. Then, we should set <code>two_round=True</code> for the train method params. The <a href="https://github.com/microsoft/LightGBM/issues/1138#issuecomment-353857567">explanation</a> for two round is rather unclear, but it should help with memory when <code>Dataset</code> is loading from disk (rather than from a <code>numpy.array</code> in memory). For this option, I had some trouble getting it to work with categorical columns.</li>
</ol>
<p>For more details can refer to the experiments below.</p>
<h3 id="experiments"><a class="header" href="#experiments">Experiments</a></h3>
<p>I often run into memory issues running LightGBM. So here are some experiments to measure memory usage and understand how hyperparameters can affect memory usage.</p>
<p>The function of interest is the <code>fit</code> method for the learn to rank task.</p>
<pre><code class="language-python">import lightGBM as lgb
def f():
    model = lgb.LGBMRanker(**params, objective=&quot;lambdarank&quot;)
    model.fit(
        X=data,
        y=y,
        group=groups,
    )
</code></pre>
<p>The memory usage is measured using the <code>memory_profiler</code> module, which checks the memory usage at .1 second intervals. The maximum is then taken to represent the maximum memory usage of the fit function. We also take note of the size of the data itself (using <code>data.nbytes</code>) and subtract that away to get closer to the LightGBM memory usage. Do note that this memory profiling is not very rigorous, so the results are best for relative comparison within each experiment rather than across experiments.</p>
<pre><code class="language-python">from memory_profiler import memory_usage
def run(params):
    mem_usage = memory_usage(f)
    return max(mem_usage) / 1000 # GB
</code></pre>
<p>We set the default parameters as follows and generate the data this way. For the experiments below, the default parameters are used unless specified otherwise.</p>
<pre><code class="language-python">DEFAULT_PARAMS = {
    &quot;N&quot;: 200000, # number of instances
    &quot;M&quot;: 500, # feature dimension
    &quot;n_estimators&quot;: 100,
    &quot;num_leaves&quot;: 100,
    &quot;histogram_pool_size&quot;: -1,
}
data = np.random.randn(DEFAULT_PARAMS[&quot;N&quot;], DEFAULT_PARAMS[&quot;M&quot;])
groups = [20] * int(N / 20) # assume each session has 20 rows
y = np.random.randint(2, size=N) # randomly choose 0 or 1
</code></pre>
<p>Large <code>num_leaves</code> can get very memory intensive. We should not need too many leaves, so generally using <code>num_leaves &lt;= 100</code> and increasing the number of estimators seems sensible to Gme.</p>
<ul>
<li>num_leaves: <code>10</code>, Maximum memory usage: 2.28 GB - 0.80 GB = <code>1.48 GB</code></li>
<li>num_leaves: <code>100</code>, Maximum memory usage: 2.52 GB - 0.80 GB = <code>1.72 GB</code></li>
<li>num_leaves: <code>1000</code>, Maximum memory usage: 4.04 GB - 0.80 GB = <code>3.24 GB</code></li>
</ul>
<p>Increasing <code>n_estimators</code> doesn't seem to raise memory much, but increases run time because each tree is fitted sequentially on the residual errors, so it cannot be parallelized.</p>
<ul>
<li>n_estimators: <code>10</code>, Maximum memory usage: 2.28 GB - 0.80 GB = <code>1.48 GB</code></li>
<li>n_estimators: <code>100</code>, Maximum memory usage: 2.53 GB - 0.80 GB = <code>1.73 GB</code></li>
<li>n_estimators: <code>1000</code>, Maximum memory usage: 2.69 GB - 0.80 GB = <code>1.89 GB</code></li>
</ul>
<p>Increasing <code>N</code> increases memory sublinearly. It seems that the data size itself will be more of a problem than the increase in LightGBM memory usage as <code>N</code> increases. For extremely large <code>N</code>, we can also set the <code>subsample</code> parameter to use only a fraction of the training instances for each step (i.e. stochastic rather than full gradient descent). By default <code>subsample=1.0</code>.</p>
<ul>
<li>N: <code>1,000</code>, Maximum memory usage: 0.38 GB - 0.00 GB = <code>0.38 GB</code></li>
<li>N: <code>10,000</code>, Maximum memory usage: 0.45 GB - 0.04 GB = <code>0.41 GB</code></li>
<li>N: <code>100,000</code>, Maximum memory usage: 1.46 GB - 0.40 GB = <code>1.06 GB</code></li>
<li>N: <code>1,000,000</code>, Maximum memory usage: 6.12 GB - 4.00 GB = <code>2.12 GB</code></li>
<li>N: <code>2,000,000</code>, Maximum memory usage: 10.48 GB - 8.00 GB = <code>2.48 GB</code></li>
</ul>
<p>In contrast to <code>N</code>, memory usage is quite sensitive to <code>M</code>, seems to increase linearly when <code>M</code> gets large. <code>M=10,000</code> blows up my memory. I suppose this could be mitigated by setting <code>colsample_bytree</code> or <code>colsample_bynode</code> to sample a smaller subset.</p>
<ul>
<li>M: <code>100</code>, Maximum memory usage: 2.08 GB - 0.16 GB = <code>1.92 GB</code></li>
<li>M: <code>1000</code>, Maximum memory usage: 4.92 GB - 1.60 GB = <code>3.32 GB</code></li>
<li>M: <code>2000</code>, Maximum memory usage: 9.69 GB - 3.20 GB = <code>6.49 GB</code></li>
<li>M: <code>3000</code>, Maximum memory usage: 14.35 GB - 4.80 GB = <code>9.55 GB</code></li>
</ul>
<p>To deal with the high memory usage of large <code>M</code>, we can set <code>colsample_bytree</code> which samples a subset of columns before training each tree. This will help to mitigate the memory usage. For this experiment, we set <code>M=2000</code> to simulate data with high number of dimensions.</p>
<ul>
<li><code>colsample_bytree</code>: 0.1, Maximum memory usage: 8.60 GB - 3.20 GB = <code>5.40 GB</code></li>
<li><code>colsample_bytree</code>: 0.2, Maximum memory usage: 9.58 GB - 3.20 GB = <code>6.38 GB</code></li>
<li><code>colsample_bytree</code>: 0.4, Maximum memory usage: 10.06 GB - 3.20 GB = <code>6.86 GB</code></li>
<li><code>colsample_bytree</code>: 0.6, Maximum memory usage: 10.07 GB - 3.20 GB = <code>6.87 GB</code></li>
<li><code>colsample_bytree</code>: 0.8, Maximum memory usage: 10.46 GB - 3.20 GB = <code>7.26 GB</code></li>
</ul>
<p>In contrast, setting <code>colsample_bynode</code> does not help memory usage at all. Not too sure why, but I suppose since multiple nodes for the same tree can be split at the same time, the full feature set still has to be kept in memory.</p>
<ul>
<li><code>colsample_bynode</code>: 0.1, Maximum memory usage: 10.49 GB - 3.20 GB = <code>7.29 GB</code></li>
<li><code>colsample_bynode</code>: 0.2, Maximum memory usage: 10.49 GB - 3.20 GB = <code>7.29 GB</code></li>
<li><code>colsample_bynode</code>: 0.4, Maximum memory usage: 10.49 GB - 3.20 GB = <code>7.29 GB</code></li>
<li><code>colsample_bynode</code>: 0.6, Maximum memory usage: 10.49 GB - 3.20 GB = <code>7.29 GB</code></li>
<li><code>colsample_bynode</code>: 0.8, Maximum memory usage: 10.48 GB - 3.20 GB = <code>7.28 GB</code></li>
</ul>
<p>Tweaking <code>boosting</code> and <code>data_sample_strategy</code> don't seem to affect memory usage too much. Using <code>dart</code> seems to require a bit more memory than the traditional <code>gbdt</code>.</p>
<ul>
<li><code>data_sample_strategy</code>: bagging, <code>boosting</code>: gbdt, Maximum memory usage: 8.90 GB - 3.20 GB = <code>5.70 GB</code></li>
<li><code>data_sample_strategy</code>: goss, <code>boosting</code>: gbdt, Maximum memory usage: 9.58 GB - 3.20 GB = <code>6.38 GB</code></li>
<li><code>data_sample_strategy</code>: bagging, <code>boosting</code>: dart, Maximum memory usage: 9.81 GB - 3.20 GB = <code>6.61 GB</code></li>
<li><code>data_sample_strategy</code>: goss, <code>boosting</code>: dart, Maximum memory usage: 9.80 GB - 3.20 GB = <code>6.60 GB</code></li>
</ul>
<p>Another bottleneck we can tackle is to realize that LightGBM is a two-stage algorithm. In the first stage, LightGBM uses the full dataset to construct bins for each numeric variable (controlled by the <code>max_bins</code> argument) based on the optimal splits. In the second stage, these discretized bins are then used to map and split the numeric variables during the actual training process to contruct trees. From my understanding, the first stage cannot be chunked as it requires the full dataset, but the second stage can be chunked (as per any stochastic gradient descent algorithm) where a fraction of the dataset is loaded at each time. Hence, the real bottleneck appears to be the first stage, when the bins are constructed.</p>
<p>According to this <a href="https://github.com/microsoft/LightGBM/issues/1146">thread</a>, we can separate the memory usage between the two stages by using <code>lgb.Dataset</code>. First, we initialize the Dataset object and make sure to set <code>free_raw_data=True</code> (this tells it to free the original data array after the binning is done). Then, we trigger the actual dataset construction using <code>dataset.construct()</code>. Thereafter, we are free to delete the original data array to free up memory for the actual training. The following code illustrates this concept.</p>
<pre><code class="language-python">dataset = lgb.Dataset(data=data, label=y, group=groups, free_raw_data=True)
del data
dataset.construct()
lgb.train(params=params, train_set=dataset)
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="intro.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="tfidf.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="intro.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="tfidf.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
