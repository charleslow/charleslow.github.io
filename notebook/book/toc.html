<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- sidebar iframe generated using mdBook

        This is a frame, and not included directly in the page, to control the total size of the
        book. The TOC contains an entry for each page, so if each page includes a copy of the TOC,
        the total size of the page becomes O(n**2).

        The frame is only used as a fallback when JS is turned off. When it's on, the sidebar is
        instead added to the main page by `toc.js` instead. The JavaScript mode is better
        because, when running in a `file:///` URL, the iframed page would not be Same-Origin as
        the rest of the page, so the sidebar and the main page theme would fall out of sync.
        -->
        <meta charset="UTF-8">
        <meta name="robots" content="noindex">
        <!-- Custom HTML head -->
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="katex.min.css">
    </head>
    <body class="sidebar-iframe-inner">
        <ol class="chapter"><li class="chapter-item expanded affix "><a href="intro.html" target="_parent">Introduction</a></li><li class="chapter-item expanded "><a href="current.html" target="_parent"><strong aria-hidden="true">1.</strong> Current Focus</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">2.</strong> Recommender Systems</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="recsys/recent_trends.html" target="_parent"><strong aria-hidden="true">2.1.</strong> Recent Trends</a></li><li class="chapter-item expanded "><a href="recsys/gradient_boosting.html" target="_parent"><strong aria-hidden="true">2.2.</strong> Gradient Boosting</a></li><li class="chapter-item expanded "><a href="recsys/tfidf.html" target="_parent"><strong aria-hidden="true">2.3.</strong> TF-IDF</a></li><li class="chapter-item expanded "><a href="recsys/cross_encoders.html" target="_parent"><strong aria-hidden="true">2.4.</strong> Cross Encoders</a></li><li class="chapter-item expanded "><a href="recsys/sentence_transformers.html" target="_parent"><strong aria-hidden="true">2.5.</strong> SentenceTransformers</a></li><li class="chapter-item expanded "><a href="recsys/collab_filtering.html" target="_parent"><strong aria-hidden="true">2.6.</strong> Collaborative Filtering</a></li><li class="chapter-item expanded "><a href="recsys/evaluation.html" target="_parent"><strong aria-hidden="true">2.7.</strong> Evaluation</a></li></ol></li><li class="chapter-item expanded "><a href="ab_test/init.html" target="_parent"><strong aria-hidden="true">3.</strong> AB Testing</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ab_test/examples.html" target="_parent"><strong aria-hidden="true">3.1.</strong> Examples</a></li><li class="chapter-item expanded "><a href="ab_test/power_analysis.html" target="_parent"><strong aria-hidden="true">3.2.</strong> Power Analysis</a></li></ol></li><li class="chapter-item expanded "><a href="llm/llm.html" target="_parent"><strong aria-hidden="true">4.</strong> LLMs</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="llm/prompt_optimization.html" target="_parent"><strong aria-hidden="true">4.1.</strong> Auto Prompt Optimization</a></li><li class="chapter-item expanded "><a href="llm/fine_tuning.html" target="_parent"><strong aria-hidden="true">4.2.</strong> Fine-tuning</a></li><li class="chapter-item expanded "><a href="llm/useful_models.html" target="_parent"><strong aria-hidden="true">4.3.</strong> Useful Models</a></li><li class="chapter-item expanded "><a href="llm/encoder_vs_decoder.html" target="_parent"><strong aria-hidden="true">4.4.</strong> Encoder vs Decoder</a></li><li class="chapter-item expanded "><a href="llm/contextualized_recs.html" target="_parent"><strong aria-hidden="true">4.5.</strong> Contextualized Recommendations</a></li></ol></li><li class="chapter-item expanded "><a href="misc.html" target="_parent"><strong aria-hidden="true">5.</strong> Miscellaneous</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="misc/bradley-terry.html" target="_parent"><strong aria-hidden="true">5.1.</strong> Bradley-Terry Model</a></li><li class="chapter-item expanded "><a href="misc/wsl-setup.html" target="_parent"><strong aria-hidden="true">5.2.</strong> Setting up WSL</a></li><li class="chapter-item expanded "><a href="misc/to-read.html" target="_parent"><strong aria-hidden="true">5.3.</strong> To Read</a></li><li class="chapter-item expanded "><a href="misc/packages.html" target="_parent"><strong aria-hidden="true">5.4.</strong> Packages</a></li><li class="chapter-item expanded "><a href="misc/skills.html" target="_parent"><strong aria-hidden="true">5.5.</strong> Skills</a></li><li class="chapter-item expanded "><a href="misc/hash_collision.html" target="_parent"><strong aria-hidden="true">5.6.</strong> Hash Collisions</a></li></ol></li><li class="chapter-item expanded "><a href="identities.html" target="_parent"><strong aria-hidden="true">6.</strong> Identities</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="identities/sigmoid.html" target="_parent"><strong aria-hidden="true">6.1.</strong> Sigmoid</a></li><li class="chapter-item expanded "><a href="identities/statistics.html" target="_parent"><strong aria-hidden="true">6.2.</strong> Statistics</a></li></ol></li><li class="chapter-item expanded "><a href="papers.html" target="_parent"><strong aria-hidden="true">7.</strong> Papers</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="papers/weinberger_2009.html" target="_parent"><strong aria-hidden="true">7.1.</strong> Weinberger 2009 - Hashing for Multitask Learning</a></li><li class="chapter-item expanded "><a href="papers/rendle_2009.html" target="_parent"><strong aria-hidden="true">7.2.</strong> Rendle 2009 - Bayesian Personalized Ranking</a></li><li class="chapter-item expanded "><a href="papers/burges_2010.html" target="_parent"><strong aria-hidden="true">7.3.</strong> Burges 2010 - RankNET to LambdaMART</a></li><li class="chapter-item expanded "><a href="papers/schroff_2015.html" target="_parent"><strong aria-hidden="true">7.4.</strong> Schroff 2015 - FaceNET</a></li><li class="chapter-item expanded "><a href="papers/covington_2016.html" target="_parent"><strong aria-hidden="true">7.5.</strong> Covington 2016 - Deep NNs for Youtube Recs</a></li><li class="chapter-item expanded "><a href="papers/schnabel_2016.html" target="_parent"><strong aria-hidden="true">7.6.</strong> Schnabel 2016 - Recs as Treatments</a></li><li class="chapter-item expanded "><a href="papers/bateni_2017.html" target="_parent"><strong aria-hidden="true">7.7.</strong> Bateni 2017 - Affinity Clustering</a></li><li class="chapter-item expanded "><a href="papers/guo_2017.html" target="_parent"><strong aria-hidden="true">7.8.</strong> Guo 2017 - DeepFM</a></li><li class="chapter-item expanded "><a href="papers/hamilton_2017.html" target="_parent"><strong aria-hidden="true">7.9.</strong> Hamilton 2017 - GraphSAGE</a></li><li class="chapter-item expanded "><a href="papers/ma_2018.html" target="_parent"><strong aria-hidden="true">7.10.</strong> Ma 2018 - Entire Space Multi-Task Model</a></li><li class="chapter-item expanded "><a href="papers/kang_2018.html" target="_parent"><strong aria-hidden="true">7.11.</strong> Kang 2018 - SASRec</a></li><li class="chapter-item expanded "><a href="papers/reimers_2019.html" target="_parent"><strong aria-hidden="true">7.12.</strong> Reimers 2019 - Sentence-BERT</a></li><li class="chapter-item expanded "><a href="papers/yi_2019.html" target="_parent"><strong aria-hidden="true">7.13.</strong> Yi 2019 - LogQ Correction for In Batch Sampling</a></li><li class="chapter-item expanded "><a href="papers/zhao_2019.html" target="_parent"><strong aria-hidden="true">7.14.</strong> Zhao 2019 - Recommending What to Watch Next</a></li><li class="chapter-item expanded "><a href="papers/lee_2020.html" target="_parent"><strong aria-hidden="true">7.15.</strong> Lee 2020 - Large Scale Video Representation Learning</a></li><li class="chapter-item expanded "><a href="papers/he_2020.html" target="_parent"><strong aria-hidden="true">7.16.</strong> He 2020 - LightGCN</a></li><li class="chapter-item expanded "><a href="papers/lewis_2020.html" target="_parent"><strong aria-hidden="true">7.17.</strong> Lewis 2020 - Retrieval Augmented Generation</a></li><li class="chapter-item expanded "><a href="papers/gao_2021_gradcache.html" target="_parent"><strong aria-hidden="true">7.18.</strong> Gao 2021 - GradCache</a></li><li class="chapter-item expanded "><a href="papers/gao_2021.html" target="_parent"><strong aria-hidden="true">7.19.</strong> Gao 2021 - SimCSE</a></li><li class="chapter-item expanded "><a href="papers/weng_2021.html" target="_parent"><strong aria-hidden="true">7.20.</strong> Weng 2021 - Contrastive Representation Learning</a></li><li class="chapter-item expanded "><a href="papers/dao_2022.html" target="_parent"><strong aria-hidden="true">7.21.</strong> Dao 2022 - Flash Attention</a></li><li class="chapter-item expanded "><a href="papers/li_2021.html" target="_parent"><strong aria-hidden="true">7.22.</strong> Li 2021 - TaoBao Embedding-Based Retrieval</a></li><li class="chapter-item expanded "><a href="papers/zou_2021.html" target="_parent"><strong aria-hidden="true">7.23.</strong> Zou 2021 - PLM Based Ranking in Baidu Search</a></li><li class="chapter-item expanded "><a href="papers/huang_2022.html" target="_parent"><strong aria-hidden="true">7.24.</strong> Huang 2022 - LLMs can Self Improve</a></li><li class="chapter-item expanded "><a href="papers/tunstall_2022.html" target="_parent"><strong aria-hidden="true">7.25.</strong> Tunstall 2022 - SetFit</a></li><li class="chapter-item expanded "><a href="papers/rafailov_2023.html" target="_parent"><strong aria-hidden="true">7.26.</strong> Rafailov 2023 - Direct Preference Optimization</a></li><li class="chapter-item expanded "><a href="papers/blecher_2023.html" target="_parent"><strong aria-hidden="true">7.27.</strong> Blecher 2023 - Nougat</a></li><li class="chapter-item expanded "><a href="papers/dong_2023.html" target="_parent"><strong aria-hidden="true">7.28.</strong> Dong 2023 - MINE Loss</a></li><li class="chapter-item expanded "><a href="papers/liu_2023.html" target="_parent"><strong aria-hidden="true">7.29.</strong> Liu 2023 - Meaning Representations from Trajectories</a></li><li class="chapter-item expanded "><a href="papers/klenitskiy_2023.html" target="_parent"><strong aria-hidden="true">7.30.</strong> Klenitskiy 2023 - BERT4Rec vs SASRec</a></li><li class="chapter-item expanded "><a href="papers/singh_2023.html" target="_parent"><strong aria-hidden="true">7.31.</strong> Singh 2023 - Semantic IDs for Recs</a></li><li class="chapter-item expanded "><a href="papers/borisyuk_2024.html" target="_parent"><strong aria-hidden="true">7.32.</strong> Borisyuk 2024 - GNN at LinkedIn</a></li><li class="chapter-item expanded "><a href="papers/wang_2024.html" target="_parent"><strong aria-hidden="true">7.33.</strong> Wang 2024 - LLM for Pinterest Search</a></li><li class="chapter-item expanded "><a href="papers/solatorio_2024.html" target="_parent"><strong aria-hidden="true">7.34.</strong> Solatorio 2024 - GISTEmbed</a></li><li class="chapter-item expanded "><a href="papers/sanjabi_2025.html" target="_parent"><strong aria-hidden="true">7.35.</strong> Sanjabi 2025 - 360Brew</a></li><li class="chapter-item expanded "><a href="papers/zhang_2025.html" target="_parent"><strong aria-hidden="true">7.36.</strong> Zhang 2025 - Qwen3 Embedding</a></li></ol></li><li class="chapter-item expanded "><a href="nlp_course/intro.html" target="_parent"><strong aria-hidden="true">8.</strong> NLP Course</a></li><li class="chapter-item expanded "><a href="database_course/intro.html" target="_parent"><strong aria-hidden="true">9.</strong> Database Course</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="database_course/lecture01.html" target="_parent"><strong aria-hidden="true">9.1.</strong> Lecture 1</a></li><li class="chapter-item expanded "><a href="database_course/lecture02.html" target="_parent"><strong aria-hidden="true">9.2.</strong> Lecture 2</a></li><li class="chapter-item expanded "><a href="database_course/lecture03.html" target="_parent"><strong aria-hidden="true">9.3.</strong> Lecture 3</a></li></ol></li><li class="chapter-item expanded "><a href="rl_course/main.html" target="_parent"><strong aria-hidden="true">10.</strong> RL Course</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="rl_course/lecture01.html" target="_parent"><strong aria-hidden="true">10.1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="rl_course/lecture02.html" target="_parent"><strong aria-hidden="true">10.2.</strong> MDPs</a></li><li class="chapter-item expanded "><a href="rl_course/lecture03.html" target="_parent"><strong aria-hidden="true">10.3.</strong> Dynamic Programming</a></li><li class="chapter-item expanded "><a href="rl_course/lecture04.html" target="_parent"><strong aria-hidden="true">10.4.</strong> Model Free Prediction</a></li><li class="chapter-item expanded "><a href="rl_course/lecture05.html" target="_parent"><strong aria-hidden="true">10.5.</strong> Model Free Control</a></li><li class="chapter-item expanded "><a href="rl_course/lecture06.html" target="_parent"><strong aria-hidden="true">10.6.</strong> Value Function Approximation</a></li></ol></li></ol>
    </body>
</html>
