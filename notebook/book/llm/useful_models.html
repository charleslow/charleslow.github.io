<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Useful Models - Chux&#x27;s Notebook</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../katex.min.css">

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="../intro.html">Introduction</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">1.</strong> Recommender Systems</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="../gradient_boosting.html"><strong aria-hidden="true">1.1.</strong> Gradient Boosting</a></li><li class="chapter-item expanded "><a href="../tfidf.html"><strong aria-hidden="true">1.2.</strong> TF-IDF</a></li><li class="chapter-item expanded "><a href="../cross_encoders.html"><strong aria-hidden="true">1.3.</strong> Cross Encoders</a></li><li class="chapter-item expanded "><a href="../sentence_transformers.html"><strong aria-hidden="true">1.4.</strong> SentenceTransformers</a></li></ol></li><li class="chapter-item expanded "><a href="../ab_test/init.html"><strong aria-hidden="true">2.</strong> AB Testing</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../ab_test/examples.html"><strong aria-hidden="true">2.1.</strong> Examples</a></li><li class="chapter-item expanded "><a href="../ab_test/power_analysis.html"><strong aria-hidden="true">2.2.</strong> Power Analysis</a></li></ol></li><li class="chapter-item expanded "><a href="../llm/llm.html"><strong aria-hidden="true">3.</strong> LLMs</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../llm/fine_tuning.html"><strong aria-hidden="true">3.1.</strong> Fine-tuning</a></li><li class="chapter-item expanded "><a href="../llm/useful_models.html" class="active"><strong aria-hidden="true">3.2.</strong> Useful Models</a></li><li class="chapter-item expanded "><a href="../llm/encoder_vs_decoder.html"><strong aria-hidden="true">3.3.</strong> Encoder vs Decoder</a></li></ol></li><li class="chapter-item expanded "><a href="../misc.html"><strong aria-hidden="true">4.</strong> Miscellaneous</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../misc/bradley-terry.html"><strong aria-hidden="true">4.1.</strong> Bradley-Terry Model</a></li></ol></li><li class="chapter-item expanded "><a href="../identities.html"><strong aria-hidden="true">5.</strong> Identities</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../identities/sigmoid.html"><strong aria-hidden="true">5.1.</strong> Sigmoid</a></li><li class="chapter-item expanded "><a href="../identities/statistics.html"><strong aria-hidden="true">5.2.</strong> Statistics</a></li></ol></li><li class="chapter-item expanded "><a href="../papers.html"><strong aria-hidden="true">6.</strong> Papers</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../papers/burges_2010.html"><strong aria-hidden="true">6.1.</strong> Burges 2010 - RankNET to LambdaMART</a></li><li class="chapter-item expanded "><a href="../papers/schroff_2015.html"><strong aria-hidden="true">6.2.</strong> Schroff 2015 - FaceNET</a></li><li class="chapter-item expanded "><a href="../papers/schnabel_2016.html"><strong aria-hidden="true">6.3.</strong> Schnabel 2016 - Recs as Treatments</a></li><li class="chapter-item expanded "><a href="../papers/guo_2017.html"><strong aria-hidden="true">6.4.</strong> Guo 2017 - DeepFM</a></li><li class="chapter-item expanded "><a href="../papers/hamilton_2017.html"><strong aria-hidden="true">6.5.</strong> Hamilton 2017 - GraphSAGE</a></li><li class="chapter-item expanded "><a href="../papers/ma_2018.html"><strong aria-hidden="true">6.6.</strong> Ma 2018 - Entire Space Multi-Task Model</a></li><li class="chapter-item expanded "><a href="../papers/reimers_2019.html"><strong aria-hidden="true">6.7.</strong> Reimers 2019 - Sentence-BERT</a></li><li class="chapter-item expanded "><a href="../papers/he_2020.html"><strong aria-hidden="true">6.8.</strong> He 2020 - LightGCN</a></li><li class="chapter-item expanded "><a href="../papers/lewis_2020.html"><strong aria-hidden="true">6.9.</strong> Lewis 2020 - Retrieval Augmented Generation</a></li><li class="chapter-item expanded "><a href="../papers/gao_2021.html"><strong aria-hidden="true">6.10.</strong> Gao 2021 - SimCSE</a></li><li class="chapter-item expanded "><a href="../papers/weng_2021.html"><strong aria-hidden="true">6.11.</strong> Weng 2021 - Contrastive Representation Learning</a></li><li class="chapter-item expanded "><a href="../papers/dao_2022.html"><strong aria-hidden="true">6.12.</strong> Dao 2022 - Flash Attention</a></li><li class="chapter-item expanded "><a href="../papers/tunstall_2022.html"><strong aria-hidden="true">6.13.</strong> Tunstall 2022 - SetFit</a></li><li class="chapter-item expanded "><a href="../papers/rafailov_2023.html"><strong aria-hidden="true">6.14.</strong> Rafailov 2023 - Direct Preference Optimization</a></li><li class="chapter-item expanded "><a href="../papers/borisyuk_2024.html"><strong aria-hidden="true">6.15.</strong> Borisyuk 2024 - GNN at LinkedIn</a></li><li class="chapter-item expanded "><a href="../papers/liu_2023.html"><strong aria-hidden="true">6.16.</strong> Liu 2023 - Meaning Representations from Trajectories</a></li></ol></li><li class="chapter-item expanded "><a href="../nlp_course/intro.html"><strong aria-hidden="true">7.</strong> NLP Course</a></li><li class="chapter-item expanded "><a href="../database_course/intro.html"><strong aria-hidden="true">8.</strong> Database Course</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../database_course/lecture01.html"><strong aria-hidden="true">8.1.</strong> Lecture 1</a></li><li class="chapter-item expanded "><a href="../database_course/lecture02.html"><strong aria-hidden="true">8.2.</strong> Lecture 2</a></li><li class="chapter-item expanded "><a href="../database_course/lecture03.html"><strong aria-hidden="true">8.3.</strong> Lecture 3</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Chux&#x27;s Notebook</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<h1 id="useful-models"><a class="header" href="#useful-models">Useful Models</a></h1>
<p>There are too many models on Huggingface, so I try to keep track of useful ones here. Generally the <a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">open_llm_leaderboard</a> is a good place to start.</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: center">Model Name</th><th style="text-align: center"># Params (Billions)</th><th style="text-align: center">openllm score</th><th style="text-align: center">Comments</th></tr></thead><tbody>
<tr><td style="text-align: center"><a href="https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0">SOLAR-10.7B-Instruct-v1.0</a></td><td style="text-align: center">10.7B</td><td style="text-align: center">74.2</td><td style="text-align: center">This model was trained using Supervised Finetuning (SFT) and Direct Preference Optimization (DPO) for single-turn chat. Seems to be derived from Llama. Verified that the outputs are sensible.</td></tr>
</tbody></table>
</div>
<h2 id="testing-solar-107b"><a class="header" href="#testing-solar-107b">Testing SOLAR-10.7B</a></h2>
<p>Here are some results from testing out <code>SOLAR-10.7B-Instruct-v1.0</code> on Google Colab, with a T4 GPU. First we install packages and load the model. Note that we are quantizing it to <code>4bits</code> to save memory, and specifying the compute type of <code>torch.float16</code> as that is the tensor type that this model was trained in. Using <code>torch.float32</code> (which is the default) will incur unnecessary conversion cost and slow down inference.</p>
<pre><code class="language-python">%pip install transformers~=4.36 torch~=2.1.1 bitsandbytes accelerate optimum

from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig
import torch

quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.float16
)

MODEL_NAME = &quot;Upstage/SOLAR-10.7B-Instruct-v1.0&quot;
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME,
    device_map=&quot;auto&quot;,
    quantization_config=quantization_config,
)
</code></pre>
<p>We define a generate function.</p>
<pre><code class="language-python">def generate(prompt: str, max_length: int = 2048):  
    conversation = [{'role': 'user', 'content': prompt}] 
    prompt = tokenizer.apply_chat_template(conversation, tokenize=False, add_generation_prompt=True)
    inputs = tokenizer(prompt, return_tensors=&quot;pt&quot;).to(model.device)
    outputs = model.generate(**inputs, use_cache=True, max_length=max_length)
    output_text = tokenizer.decode(outputs[0])
    return output_text
</code></pre>
<p>And now we can test it out on a few prompts.</p>
<p>Prompt: <code>Can you explain web3 to a 5 year old?</code> Response: Web3 is like a special world on the internet that lets people share and use things in a new and more open way. Imagine a playground where everyone can add their own swings, slides, and sandboxes without needing permission from a big boss. This makes it easier for people to work together and create new fun things online. (Inference time: <code>8s</code>)</p>
<p>Prompt: <code>Can a firefighter transit into the finance industry?</code> Response: While it may not be a typical career transition, it is possible for a firefighter to transition into the finance industry. To make a successful move, the firefighter would need to acquire the necessary skills and qualifications relevant to the finance sector. This could involve pursuing additional education or training in finance, accounting, or business administration. Networking, gaining relevant work experience, and showcasing transferable skills from the firefighting profession can also help in making the transition.\n\nSome transferable skills from firefighting to finance could include strong problem-solving abilities, teamwork, decision-making under pressure, and the ability to manage risk. However, it's essential to note that the finance industry has its unique requirements, and the firefighter would need to demonstrate a strong commitment to learning and adapting to the new environment. (Inference time: <code>19s</code>)</p>
<p>Seems to be pretty decent performance at a somewhat reasonable inference time out of the box.</p>
<p><a href="https://huggingface.co/docs/transformers/perf_infer_gpu_one">Speeding up GPU inference</a>.</p>
<h2 id="gemma-models"><a class="header" href="#gemma-models">Gemma Models</a></h2>
<p>References:</p>
<ul>
<li><a href="https://huggingface.co/blog/gemma">Huggingface Reference</a></li>
<li><a href="https://huggingface.co/blog/gemma-peft">Fine-tuning Gemma with PEFT</a></li>
<li><a href="https://huggingface.co/google/gemma-7b">gemma-7b Model Card</a></li>
</ul>
<p>Google released open source small models under the Gemma label. It comes in two sizes: 2B and 7B parameters, each with base (pretrained) and instruction-tuned versions. All have a context length of <code>8k tokens</code>. Gemma integration is supported with <code>transformers==4.38</code>. Note that user consent is needed to access Gemma models, so one needs to create a HuggingFace account and <a href="https://huggingface.co/docs/hub/security-tokens">create an access token</a>.</p>
<h3 id="sample-code"><a class="header" href="#sample-code">Sample Code</a></h3>
<pre><code class="language-python"># Use model_name=&quot;google/gemma-7b-it&quot;
def load(model_name: str):
    tokenizer = AutoTokenizer.from_pretrained(model_name, token=TOKEN)
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        quantization_config=BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_compute_dtype=torch.bfloat16,
            bnb_4bit_use_double_quant=True,  # nested quantization
            bnb_4bit_quant_type=&quot;nf4&quot;,  # normalized quantization
        ),
        token=TOKEN,
    )
    return model, tokenizer
</code></pre>
<h3 id="inference-speed"><a class="header" href="#inference-speed">Inference Speed</a></h3>
<p>Tested out the inference speed of the model using the following prompt: <code>Can you recommend good alternative occupations for a occupation_name? Please be concise</code>. </p>
<p>An example is as follows, for an occupation <code>counsellor</code>:</p>
<pre><code>Sure, here are some alternative occupations for a counsellor:

* **Social worker:** Similar to counselling, social workers help individuals and families facing various challenges.
* **Community organizer:** Organizes and leads community initiatives to address social issues.
* **Teacher:** Can be a good fit for those who enjoy working with children and adolescents.
* **Human resource manager:** HR managers handle employee relations and conflicts.
* **Public relations specialist:** Helps organizations communicate effectively with the public.
</code></pre>
<p>The inference speed is about <code>8-10 seconds</code> with 4-bit quantization.</p>
<h3 id="gemma-2b"><a class="header" href="#gemma-2b">Gemma-2b</a></h3>
<p>Testing out <code>google/gemma-2b-it</code> shows that it has poorer performance but faster inference speed at 2 billion parameters. Here is an example of the results for the same prompt.</p>
<pre><code>* **Life coach**
* **Coach in education**
* **Career coach**
* **Executive coach**
* **Leadership coach**
* **Management consultant**
* **Business development consultant**
* **Financial advisor**
* **Investment banker**
</code></pre>
<p>The inference speed is as follows:</p>
<ul>
<li>Single: <code>3s</code></li>
<li>Batch of <code>4</code>: <code>14s</code></li>
<li>Batch of <code>8</code>: <code>16s</code></li>
<li>Batch of <code>16</code>: <code>20s</code></li>
<li>Batch of <code>32</code>: OOM on T4 GPU</li>
</ul>
<h2 id="phi-2"><a class="header" href="#phi-2">Phi-2</a></h2>
<p>Mobius Labs fine-tuned the <code>phi-2</code> model from Microsoft which seems promising, and released it under <code>mobiuslabsgmbh/aanaphi2-v0.1</code>. The output seems better than <code>gemma-2b-it</code>.</p>
<pre><code>1. Social worker
2. Mental health therapist
3. School counselor
4. Employee assistance program (EAP) specialist
5. Rehabilitation counselor
6. Family therapist
7. Substance abuse counselor
8. Career counselor
9. Trauma-focused therapist
10. Child and adolescent therapist

These occupations involve working with individuals, families, and communities to promote mental health and well-being, and may provide similar skills and experiences to those of a counsellor.
</code></pre>
<ul>
<li><a href="https://colab.research.google.com/drive/1ge2F1QSK8Q7h0hn3YKuBCOAS0bK8E0wf#scrollTo=VPD7QS_DR-mw">bitsandbytes example notebook from HuggingFace</a></li>
</ul>
<p>Flash attention, torch.compile, quantization.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../llm/fine_tuning.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../llm/encoder_vs_decoder.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../llm/fine_tuning.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../llm/encoder_vs_decoder.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
