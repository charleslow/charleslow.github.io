<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Han 2025 - GRPO Example - Chux&#x27;s Notebook</title>


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../katex.min.css">


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "../searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Chux&#x27;s Notebook</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<h1 id="han-2025---grpo-example"><a class="header" href="#han-2025---grpo-example">Han 2025 - GRPO Example</a></h1>
<p><a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/gpt-oss-(20B)-GRPO.ipynb#scrollTo=MXPZ1MsUMqNZ">Notebook Tuning GPT-OSS</a></p>
<p>This notebook shows how to finetune <code>gpt-oss-20b</code> using unsloth. The parameters used are:</p>
<pre><code class="language-python">max_seq_length = 768
lora_rank = 4
lora_alpha = lora_rank * 2
load_in_4bit = True
offload_embedding = True
</code></pre>
<p>The toy problem is to induce gpt-oss to learn how to output an optimized all python <code>matmul</code> procedure that only uses the standard library. Naturally, using optimized libraries like <code>numpy</code> will be a lot faster, but there is some room to improve from a naive implementation in pure python.</p>
<p>First, we generate some random matrices. Note that we need <code>A_list</code> and <code>B_list</code> which are <code>list[list[float]]</code> to pass to our pure python function.</p>
<pre><code class="language-python">import numpy as np
def generate_random_matrices(seed = 3407, n = 256):
    random_state = np.random.RandomState(seed)
    n, k, m = random_state.randint(1, n+1, size = 3)
    A = np.random.uniform(-10, 10, size = (n, k))
    B = np.random.uniform(-10, 10, size = (k, m))
    return A, A.tolist(), B, B.tolist()
</code></pre>
<p>For example, a kernel generated by GPT-5 is:</p>
<pre><code class="language-python"># Kernel generated by GPT-5
def matmul(A, B):
    B_transpose = list(zip(*B))
    return [
        [
            sum(a*b for a, b in zip(row, col)) 
            for col in B_transpose
        ] for row in A
    ]
</code></pre>
<h2 id="preventing-cheating"><a class="header" href="#preventing-cheating">Preventing Cheating</a></h2>
<p>GRPO works using RL with a reward function. To get the desired behaviour, we have to find a reward function that disincentivises cheating. For example, the LLM might just come up with a solution that imports <code>torch</code> or <code>numpy</code> to get an optimized matmul function.</p>
<p>Firstly, we write a function called <code>check_only_stdlib_imports</code> that, given a string representing a python function (let's call it <code>fn_string</code>), checks if it imports anything outside of the python standard library. We omit the definition here as it is rather involved.</p>
<p>Secondly, given <code>fn_string</code>, we want to compile it into a python function and disallow the function from importing anything from the global name space. The following code does so:</p>
<pre><code class="language-python">def create_locked_down_function(function: str):
    output_function = {}
    exec(function, {}, output_function)
    new_matmul = output_function["matmul"]
    new_matmul = types.FunctionType(new_matmul.__code__, {})
    return new_matmul
</code></pre>
<p>Some explanations:</p>
<ul>
<li><code>exec(string: str, globals: dict, locals: dict)</code>
<ul>
<li>This executes code in <code>string</code> and stores whatever definitions within the code into <code>locals</code></li>
<li>By specifying an empty <code>dict</code> for <code>globals</code>, we are disallowing the functions defined within to access the global namespace</li>
</ul>
</li>
<li><code>types.FunctionType(code, globals)</code>
<ul>
<li>This creates a new function from compiled python bytecode</li>
<li>It also redefines the global variables that the function can access as an empty dictionary</li>
</ul>
</li>
<li>So this function turns <code>fn_string</code> into a python function, but disallows accessing any global variables and libraries</li>
</ul>
<h2 id="benchmarking"><a class="header" href="#benchmarking">Benchmarking</a></h2>
<p>Now we create the actual benchmarking function. There are some details here that we shall gloss over, but note that at a high level, we call <code>Benchmarker.benchmark(mat_mul_fn, [A, B])</code> to get some statistics about the matrix multiplcation function we are testing.</p>
<pre><code class="language-python">import os, gc, time, statistics
import signal
from contextlib import contextmanager

class TimeoutError(Exception): pass

@contextmanager
def time_limit(seconds):
    def _handler(signum, frame):
        raise TimeoutError(f"Timed out after {seconds}s")
    old = signal.signal(signal.SIGALRM, _handler)
    signal.setitimer(signal.ITIMER_REAL, seconds)
    try:
        yield
    finally:
        signal.setitimer(signal.ITIMER_REAL, 0.0)
        signal.signal(signal.SIGALRM, old)

class Benchmarker:
    def __init__(self, trials = 3, loops = 1, timeout = 30):
        self.buffer = np.zeros(2 * 1024 * 1024 * 1024, dtype = np.uint8)
        self.trials = trials
        self.loops = loops
        assert timeout &gt; 0 # Cannot be 0 since it won't work!
        self.timeout = timeout

    def thrash(self):
        # Edit the buffer to wipe cache lines
        self.buffer ^= 1
        return int(self.buffer[::4096].sum())

    def benchmark(self, function, arguments):
        assert len(arguments) == self.loops
        samples = []
        exceptions = []
        timed_out = 0
        for _ in range(self.trials):
            gc.collect(); gc.disable(); self.thrash()
            t_start = time.perf_counter_ns()
            for i in range(self.loops):
                try:
                    with time_limit(self.timeout):
                        function(*arguments[i])
                except TimeoutError as e:
                    timed_out += 1
                except Exception as e:
                    exceptions.append(str(e))
            t_end = time.perf_counter_ns()
            gc.enable()
            samples.append((t_end - t_start) // max(1, self.loops))
        return {
            "median_ns": int(statistics.median(samples)),
            "mean_ns": int(statistics.fmean(samples)),
            "stdev_ns": int(statistics.pstdev(samples) if len(samples) &gt; 1 else 0),
            "exceptions" : exceptions,
            "timeouts" : timed_out,
        }
</code></pre>
<p>Some other details:</p>
<ul>
<li>A timeout is added to raise an error if the function runs for too long</li>
<li><code>gc</code> is handled to avoid garbage collection from messing up the trial timing</li>
<li>Some thrashing of a large <code>2GB</code> buffer is done to wipe out the L1, L2, L3 CPU caches to avoid the CPU from tapping on the cache to fast track the computation</li>
</ul>
<h2 id="generate-matmul-function"><a class="header" href="#generate-matmul-function">Generate matmul function</a></h2>
<p>Now we get gpt-oss to generate some matmul function, like so.</p>
<pre><code class="language-python">from transformers import TextStreamer

prompt = """
Create a new fast matrix multiplication function using only native Python code.
You are given a list of list of numbers.
Output your new function in backticks using the format below:
```python
def matmul(A, B):
    return ...
```
""".strip()

text = tokenizer.apply_chat_template(
    [{"role": "user", "content": prompt}],
    tokenize = False,
    add_generation_prompt = True,
    reasoning_effort = "low",
)
_ = model.generate(
    **tokenizer(text, return_tensors = "pt").to("cuda"),
    temperature = 1.0,
    max_new_tokens = 512,
    streamer = TextStreamer(tokenizer, skip_prompt = False),
)
</code></pre>
<p>Which will give something like:</p>
<pre><code class="language-bash">...

```python
def matmul(A, B):
    """
    Multiply two matrices A and B where both are given as
    lists of lists (rows) and are compatible for multiplication.
    Returns the resulting matrix as a list of lists.
    """
    # Transpose B so we can access its columns as rows.
    B_T = [list(col) for col in zip(*B)]          # O(n*m) time
    result = []

    for row in A:                                 # for each row in A
        res_row = []
        for col in B_T:                           # for each column of B
            # Compute dot product of row and column
            dot = sum(a * b for a, b in zip(row, col))
            res_row.append(dot)
        result.append(res_row)

    return result
```
...
</code></pre>
<h2 id="reward-functions"><a class="header" href="#reward-functions">Reward functions</a></h2>
<p>Now we want to build up our reward function which assigns a reward score to each new generation from gpt-oss. The flow is:</p>
<ul>
<li>Extract the function from a generation text</li>
<li>Use <code>create_locked_down_function</code> to turn it into python code</li>
<li>Use <code>Benchmarker</code> to test how fast it is</li>
<li>Using benchmark statistics, assign some scores</li>
</ul>
<p>First we define <code>extract_function(generation_text: str)</code> which simply extracts the function from a generation text by looking for the triple-backticks. Omitted for brevity.</p>
<p>Next we create multiple reward functions that test different aspects. For example, we have <code>function_works</code> which just checks that the function runs without errors. Note that the function runs on a list of completions.</p>
<pre><code class="language-python">def function_works(completions, **kwargs):
    scores = []
    for completion in completions:
        score = 0
        response = completion[0]["content"]
        function = extract_function(response)
        print(function)
        if function is not None:
            ok, info = check_only_stdlib_imports(function)
        if function is None or "error" in info:
            score = -2.0
        else:
            try:
                new_matmul = create_locked_down_function(function)
                score = 1.0
            except:
                score = -0.5
        scores.append(score)
    return scores
</code></pre>
<p>Another reward function checks that the function is correct. As we can see, the score is higher for more accurate functions and lower for inaccurate functions.</p>
<pre><code class="language-python">def correctness_check(completions, **kwargs):
    scores = []
    # Generate some random matrices of size less than 128
    A, A_list, B, B_list = generate_random_matrices(seed = np.random.randint(10000), n = 128)
    for completion in completions:
        score = 0
        response = completion[0]["content"]
        function = extract_function(response)
        if function is not None:
            ok, info = check_only_stdlib_imports(function)
        if function is None or "error" in info:
            scores.append(0)
            continue
        try:
            new_matmul = create_locked_down_function(function)
        except:
            scores.append(0)
            continue
        try:
            pred = new_matmul(A_list.copy(), B_list.copy())
        except:
            # Failed!
            scores.append(-2.0)
            continue
        true = np.matmul(A, B)
        amax_error, mse_error = calculate_difference(pred, true)

        # Check correctness and score!
        machine_epsilon = 100*np.finfo(np.float64).eps
        if   amax_error &gt;= 3:   score = -3.0
        elif amax_error &gt;= 2:   score = -2.5
        elif amax_error &gt;= 1:   score = -2.0
        elif amax_error &gt;= 0.5: score = -1.0
        elif amax_error &gt;= 100*machine_epsilon: score = 0.0
        elif amax_error &gt;= machine_epsilon: score = 1.0
        else: score = 3.0

        if   mse_error &gt;= 3:   score += -3.0
        elif mse_error &gt;= 2:   score += -2.5
        elif mse_error &gt;= 1:   score += -2.0
        elif mse_error &gt;= 0.5: score += -1.0
        elif mse_error &gt;= 100*machine_epsilon: score += 0.0
        elif mse_error &gt;= machine_epsilon: score += 1.0
        else: score += 3.0
        scores.append(score)
    return scores
</code></pre>
<p>Finally we have the speed check function which rewards fast implementations.</p>
<ul>
<li>If the LLM implementation is faster than numpy implementation, then <code>positive</code> is used (e.g. 2x faster gives <code>+0.02</code>)</li>
<li>If the LLM implementation is slower than numply implementation, then <code>negative</code> is used (e.g. 2x slower gives <code>-0.02</code>)</li>
</ul>
<pre><code class="language-python">import gc
def speed_check(completions, **kwargs):
    scores = []
    # Generate some random matrices of size less than 256
    A, A_list, B, B_list = generate_random_matrices(seed = np.random.randint(10000), n = 256)
    numpy_results = benchmarker.benchmark(np.matmul, [(A, B)])
    for completion in completions:
        score = 0
        response = completion[0]["content"]
        function = extract_function(response)
        if function is not None:
            ok, info = check_only_stdlib_imports(function)
        if function is None or "error" in info:
            scores.append(0)
            continue
        try:
            new_matmul = create_locked_down_function(function)
        except:
            scores.append(0)
            continue
        new_results = benchmarker.benchmark(new_matmul, [(A_list.copy(), B_list.copy())])

        # Get score and clip to -10, 10
        negative = -(new_results["median_ns"] / numpy_results["median_ns"]) / 100
        positive = +(numpy_results["median_ns"] / new_results["median_ns"]) / 100
        score = negative if new_results["median_ns"] &gt;= numpy_results["median_ns"] else positive
        if score &gt;= 10:  score = 10
        if score &lt;= -10: score = -10
        scores.append(score)
    # Free memory to counteract OOMs
    gc.collect()
    torch.cuda.empty_cache()
    return scores
</code></pre>
<h2 id="grpotrainer"><a class="header" href="#grpotrainer">GRPOTrainer</a></h2>
<p>Finally, we can prepare our dataset and set up the <code>GRPOTrainer</code>.</p>
<p>First, we create a dataset with just the <code>prompt</code>. We just need the prompt because we're running this in dynamic mode, where <code>GRPOTrainer</code> will sample a few generations for each prompt and evaluate it using the reward functions. This represents true on-policy RL.</p>
<p>Note also that we use <code>reasoning_effort="low"</code>.</p>
<pre><code class="language-python">from datasets import Dataset
dataset = Dataset.from_list([{"prompt" : [{"role": "user", "content": prompt.strip()}], "answer" : 0, "reasoning_effort": "low"}]*1000)
maximum_length = len(tokenizer(prompt.strip())["input_ids"])
print(maximum_length)
dataset[0]
</code></pre>
<p>Now we setup <code>GRPOTrainer</code> with configuration.</p>
<pre><code class="language-python">max_prompt_length = maximum_length + 1 # + 1 just in case!
max_completion_length = max_seq_length - max_prompt_length

from trl import GRPOConfig, GRPOTrainer
training_args = GRPOConfig(
    temperature = 1.0,
    learning_rate = 5e-5,
    weight_decay = 0.01,
    warmup_ratio = 0.1,
    lr_scheduler_type = "linear",
    optim = "adamw_8bit",
    logging_steps = 1,
    per_device_train_batch_size = 1,
    gradient_accumulation_steps = 1, # Increase to 4 for smoother training
    num_generations = 2, # Decrease if out of memory
    max_prompt_length = max_prompt_length,
    max_completion_length = max_completion_length,
    # num_train_epochs = 1, # Set to 1 for a full training run
    max_steps = 100,
    save_steps = 100,
    report_to = "none", # Can use Weights &amp; Biases
    output_dir = "outputs",

    # For optional training + evaluation
    # fp16_full_eval = True,
    # per_device_eval_batch_size = 4,
    # eval_accumulation_steps = 1,
    # eval_strategy = "steps",
    # eval_steps = 1,
)
</code></pre>
<p>Finally we can train the model. Note that T4 GPU might take 5 minutes for one generation which might take hours to start seeing some progress on this task.</p>
<pre><code class="language-python"># For optional training + evaluation
# new_dataset = dataset.train_test_split(test_size = 0.01)

trainer = GRPOTrainer(
    model = model,
    processing_class = tokenizer,
    reward_funcs = [
        function_works,
        no_cheating,
        correctness_check,
        speed_check,
    ],
    args = training_args,
    train_dataset = dataset,

    # For optional training + evaluation
    # train_dataset = new_dataset["train"],
    # eval_dataset = new_dataset["test"],
)
trainer.train()
</code></pre>
<p>After training, we can use our original prompt to see the new function that the LLM generates.</p>
<pre><code class="language-python">text = tokenizer.apply_chat_template(
    [{"role": "user", "content": prompt}],
    tokenize = False,
    add_generation_prompt = True,
    reasoning_effort = "low",
)

from transformers import TextStreamer
_ = model.generate(
    **tokenizer(text, return_tensors = "pt").to("cuda"),
    temperature = 1.0,
    max_new_tokens = 1024,
    streamer = TextStreamer(tokenizer, skip_prompt = False),
)
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../talks/hameed_2025_360brew.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../nlp_course/intro.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../talks/hameed_2025_360brew.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../nlp_course/intro.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->
        <script src="../mermaid.min.js"></script>
        <script src="../mermaid-init.js"></script>



    </div>
    </body>
</html>
