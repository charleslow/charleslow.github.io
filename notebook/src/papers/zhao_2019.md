# Zhao 2019 - Recommending What to Watch Next

[Recommending What Video to Watch Next: A Multitask Ranking System](https://daiwk.github.io/assets/youtube-multitask.pdf)

This paper covers Youtube's recommendation system for what video to watch next, given the current video. The main contributions of this paper are:
- Handling position bias
- Multi-gated Mixture of Experts to handle multi-task objectives

## Background

This paper focuses on the ranking task of next video recommendation. There are specific challenges to their setting:
1. <<Multiple signals>>. For each video recommendation, there are <<engagement signals>> such as clicked, duration watched etc., and also <<user satisfaction signals>> such as liked, shared etc. Optimizing for these tasks is potentially conflicting, but multi-task learning also has potential to learned shared representations across tasks.
2. <<Position bias>>. Position bias can degrade recommender performance since it may learn signals irrelevant to relevance. Tackling this issue can lead to online performance gains.
3. <<Large Scale>>. The industry scale of recommending from billions of videos means that training quality might need to be traded off for efficiency. For this reason, the paper opts for a neural network based point-wise ranking model (as opposed to pair-wise or list-wise training methods like InfoNCE). This is also why the paper focuses on an architecture that can efficiently share parameters between different input feature modalities and prediction tasks.

The candidate generation is performed using a sequence model similar to [Covington 2016 - Deep Neural Networks for YouTube Recommendations](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf). The efficient gramian methods in [Krichene 2018 - Efficient Training on Very Large Corpora via Gramian Estimation](https://arxiv.org/abs/1807.07187) was also used.



