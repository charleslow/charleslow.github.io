# He 2020 - LightGCN

[He 2020 - LightGCN](https://arxiv.org/pdf/2002.02126.pdf) is a simple and effective Graph Convolution Network for recommendation.


LightGCN is an adaptation of Graph Convolutional Neural Networks (GCN) to the task of recommendations. In a typical Convolutional Neural Network for vision, convolution aggregations (such as linear projections, pooling, average) are applied to a <neighbourhood> of pixels that are near to one another. The aggregations transform the raw pixel values into a hidden layer of "embedding" values, and the next layer of aggregations is applied to the hidden layer, allowing the CNN to learn more abstract features with each increasing layer. A GCN uses essentially the same idea, except that the definition of <neighbourhood> of a node A are the neighbouring nodes that are connected by an edge to A. The GCN thus allows us to train node embeddings on all types of graphical data, such as social networks, user-item interactions etc.

## Neural Graph Collaborative Filtering (NGCF)

The LightGCN model is essentially a simplification of the NGCF model, so the paper starts here. Btw, there are some overlaps between LightGCN authors and NGCF authors. The setup is as follows:
- Each user and item are embedded from their `id` -> `embedding`
- Let $e_u^{(0)}$ denote the ID embedding of user $u$ and $e_i^{(0)}$ denote the ID embedding of item $i$

NGCF uses the user-item interaction graph (derived from data) to propagate the embeddings as follows:
$$
\begin{align*}
    e^{(k+1)}_u &= \sigma \left(
        W_1^{(k)} e_u^{(k)} + \sum_{i \in \mathcal{N}_u} \frac{1}{\sqrt{|\mathcal{N}_u| |\mathcal{N}_i|}} 
        \left(
            W^{(k)}_1 e_i^{(k)} + W^{(k)}_2 ( e^{(k)}_i \odot e^{(k)}_u)
        \right)
    \right)\\
    e^{(k+1)}_i &= \sigma \left(
        W_1^{(k)} e_i^{(k)} + \sum_{u \in \mathcal{N}_i} \frac{1}{\sqrt{|\mathcal{N}_u| |\mathcal{N}_i|}} 
        \left(
            W^{(k)}_1 e_u^{(k)} + W^{(k)}_2 ( e^{(k)}_i \odot e^{(k)}_u)
        \right)
    \right)
\end{align*}
$$

Some notes about the propagation equations above:
- $e^{(k+1)}_u$ and $e^{(k+1)}_i$ denote the embedding of user $u$ and item $i$ respectively after `k` layers of propagation
- $\sigma$ is a non-linear activation function
- $\mathcal{N}_u$ denotes the set of *items* that interacted with user $u$. For instance, it could be all the items the user purchased within the past 3 months. $\mathcal{N}_i$ is the set of *users* defined in a similar way.
- $W^{(k)}_1$ and $W^{(k)}_2$ are trainable weights

Intuitively for a given user, the equation propagates (i) the user embeddings itself (`order-1`), (ii) the embeddings of neighbouring items (`order-1`) *and* (iii) the hadamard interaction between the user and the neighbouring items (`order-2`). And likewise for the item embeddings.

Finally, after training the network of $L$ layers, we obtain $L+1$ embeddings for each user and item. The embeddings are concatenated as such $e_u = [e_u^{(0)}, ...,\ e_u^{(L)}]$ and $e_i = [e_i^{(0)}, ...,\ e_i^{(L)}]$ where $e_u, e_i$ are vectors of dimension $\R^{kL}$. Prediction scores for the match between user $u$ and item $i$ are then computed via the inner product $\langle e_u, e_i \rangle$.

## Problem With NGCF

The authors argue that NGCF is unnecessarily complicated because traditionally, the base embedding layer $e_u^{(0)}, e_i^{(0)}$ is derived from rich semantic features such as embedding the title of papers etc. This justifies the usage of the activation function $\sigma$ and the projection weights $W^{(k)}_1, W^{(k)}_2$ etc. to learn a transformation of the semantic features. In contrast, for the collaborative filtering setting, the embeddings are arbitrary numbers tied to each user or item ID. Hence, performing multiple non-linear transformations will not lead to better feature learning.

<Note>: I'm not fully convinced by this argument, although the empirical results do support it. I agree with the argument to the extent that the base embedding layer is arbitrary, but imo NGCF can still learn a bigger representation space of models through its non-linear transformations. The problem seems to be more that (i) the richer feature representation is not very useful and (ii) the additional complexity makes the model harder to learn.

## LightGCN

In LightGCN, we essentially remove the non-linear activation and weight projections. The propagation equations simplify to the following:



## References

- [Medium Post by Hikaru Hotta and Ada Zhou](https://medium.com/stanford-cs224w/lightgcn-with-pytorch-geometric-91bab836471e)
- [LightGCN Paper](https://arxiv.org/pdf/2002.02126.pdf)
- [NGCF Paper](https://arxiv.org/pdf/1905.08108.pdf)