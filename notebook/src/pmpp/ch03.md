# 03 - Multidimensional grids

In the previous chapter we considered a simple 1D kernel. In general, a grid is a three-dimensional array of blocks, and each block is a 3D array of threads. We can specify them like so:
```c
dim3 dimGrid(32, 1, 1);
dim3 dimBlock(128, 1, 1);
vecAddKernel<<<dimGrid, dimBlock>>>(...)
```

This specifies a grid with `32` blocks and each block has `128` threads. So the total number of threads in the grid is `4,096`.

Or we can let the variables be a function of something else, e.g. if `n` denotes the size of the vector:
```c
dim3 dimGrid(ceil(n/256.0), 1, 1);
dim3 dimBlock(256, 1, 1);
vecAddKernel<<<dimGrid, dimBlock>>>(...)
```

This fixes the number of threads per block at `256` and the number of blocks varies with the size of the vector.

For convenience, if we are specifying 1D grids and blocks, we can just use a single number to represent it.

In CUDA C, the allowable range of values:
- `gridDim.x` varies from $1$ to $2^{31}-1$
- `gridDim.y`, `gridDim.z` varies from $1$ to $2^{16}-1 = 65,535$
- Consequently, `blockDim.x` ranges from $0$ to `gridDim.x-1` and so on

The total size of a block in current CUDA systems is limited to `1024` threads. These threads can be distributed across three dimensions in any way as long as the total number of threads does not exceed `1024`. 

The dimensions of the number of blocks in a grid and the dimensions of the number of threads in a block need not match up.

Sometimes, we need to refer to the index of a specific block in the grid or a specific thread in a block. The idiomatic way is:
- Block: `(blockIdx.z, blockIdx.y, blockIdx.x)`
- Thread: `(threadIdx.z, threadIdx.y, threadIdx.z)`

Notice that the order of the index is reverse to the order of specifying the `dimGrid` or `dimBlock`. There is some reason for this, although it is not clear to me right now.

## Mapping Threads to Multidimensional Data

The choice of 1D, 2D or 3D thread organization is usually based on the nature of the data. For example, pictures are 2D and so it is conventional to choose 2D arrangements. 

Suppose we have a picture with `62 x 76` pixels, i.e. `62` in the `y` dimension and `76` in the `x` dimension. Assume we use a `16 x 16` block, with `16` threads in the `x, y` dimensions respectively. We will thus need `4` blocks in the `y` direction, and `5` blocks in the `x` direction. So for each thread:
- The vertical (row) coordinate is: `row = blockIdx.y * blockDim.y + threadIdx.y`
- The horizontal (column) coordinate is: `col = blockIdx.x * blockDim.x + threadIdx.x`

How does the kernel call look like? Suppose we have:
- `n` represents number of pixels in the `y` direction
- `m` represents the number of pixels in the `x` direction
- The picture data has been copied to device memory stored at pointer `Pin_d`

Then the host code looks like:
```c
dim3 dimGrid(ceil(m/16.0), ceil(n/16.0), 1);
dim3 dimBlock(16, 16, 1);
colorToGrayScaleConversion<<<dimGrid, dimBlock>>>(Pin_d, Pout_d, m, n);
```

## Memory Layout

Given that we have computed the row and col coordinates for each thread, ideally we would access the elements of `Pin_d` like `Pin_d[row][col]`. Unfortunately C does not allow us to do this - we are only allowed to access it as a 2D array in this manner if the dimensions of `Pin_d` is known at compile time. 

> **Memory Space**. A memory space is a simplified view of how a processor accesses its memory. A memory space is usually associated with each running application. Each location has a byte and an address. Variables that need multiple bytes are stored in consecutive byte locations. 
> 
> Since there is only one address for each location, we say that the memory space has a flat layout. Thus, all multidimensional arrays are ultimately flattened into equivalent one dimensional arrays. When a C programmer uses multidimensional syntax to access an element, the transpiler is really translating these accesses into a 1D base pointer. 

Hence, the CUDA programmer needs to explicitly linearize the 2D accesses into a 1D access. There are two ways to do this:
- <<row-major layout>>: rows are placed one after another consecutively in memory space
- <<column-major layout>>: columns are placed one after another consecutively in memory space

CUDA C uses the row-major layout; an example of the column-major layout is FORTRAN. We will thus focus on the row major layout.

Let us denote the element of interest as $M_{j,i}$, i.e. the element with `y` coordinate `j` and `x` coordinate `i`. Suppose $M$ is `4 x 4` and linearized into `16` element 1D array. In the flattened row-major layout, we access $M_{j, i}$ using:
```
j * 4 + i 
```

Now we'll tackle the 2D version of `colorToGrayscaleConversion`.

```c
__global__
void colorToGrayscaleConversion(unsigned char * Pout, 
            unsigned char * Pin, int width, int height) {
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    if (col < width && row < height) {
        int grayOffset = row*width + col;
        int rgbOffset = grayOffset * CHANNELS;
        unsigned char r = Pin[rgbOffset];
        unsigned char g = Pin[rgbOffset + 1];
        unsigned char b = Pin[rgbOffset + 2];
        Pout[grayOffset] = 0.21f*r + 0.71f*g + 0.07f*b;
    }
}
```

Notes:
- Note that the input image is encoded as unsigned chars, since they encode a value from `0-255`
    - Each pixel is represented as `3` consecutive chars representing the `3` channels
    - Thus pixel `i` starts at the char located at `i*3` position
- We first compute `grayOffset`, which corresponds to the location for the pixel we are processing
- `rgbOffset` is `3x grayOffset` because each pixel has 3 unsigned chars in the input image
- After extracting the `r, g, b` values from the input image, we compute and store the gray intensity into `Pout` using the linearized 1D acess `grayOffset`

## 3D arrays

We can easily extend the discussion of 2D arrays into 3D. The idea is that the `x * y` coordinates form a plane, and we insert each "plane" one after another into the address space.
- This means that we track a new 
    ```c 
    int plane = blockIdx.z * blockDim.z + threadIdx.z
    ```
- And access the 1D index as 
    ```c 
    P[plane*m*n + row*m + col]
    ```

## Image Blur

Image blurring is closer to a real world example. The idea of blurring is to smooth out abrupt variations in pixel values. Mathematically, it is just computing the value of an output pixel as a weightedsum of a patch of pixels surrounding the pixel in the input image. In our simple example, we will take the simple average value of the `N x N` patch of pixels surrounding our target pixel. 