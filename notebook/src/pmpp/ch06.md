# Performance Considerations

This chapter goes deeper into off chip memory (DRAM) and discusses memory coalescing and memory latency hiding. It also discusses thread granularity coarsening.

## Memory Coalescing

One of the most important factors in CUDA kernel performance is accessing data in the global memory. This chapter further discusses memory coalescing techniques to move data between global memory and shared memory or registers efficiently.

Global memory is implemented with DRAM:
- Access latency to a bit in DRAM is relatively slow (tens of nanoseconds)
- Because of this slowness, DRAM is designed to use parallelism to increase the memory access throughput

Each time a DRAM location is accessed, a range of consecutive locations nearby are accessed. Once detected by the sensors, the data from all these locations can be transferred to the processor.
- These consecutive locations assessed is known as <<DRAM bursts>>
- Making use of these consecutive and simultaneous accesses can allow us to improve memory access throughput

When a warp of threads is launched, all threads in the warp execute the same instruction at the same point in time. The hardware detects whether the threads are accessing consecutive memory locations.
- Thus, the best access pattern is for threads in a warp to access consecutive data locations in global memory
- We say that the hardware <<coalesces>> the accesses into a consoliated access to consecutive DRAM locations

Recall that multidimensional data are linearized according to the row-major convention and stored into memory space.